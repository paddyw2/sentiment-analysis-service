# -*- coding: utf-8 -*-
"""Keras Sentiment Example.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1pDWTqG6s9Tn68MO-qagBxB9P_iQR-TJL

From: https://keras.io/examples/imdb_lstm/ with epochs reduced to 3 to speed up training
"""
import re
from bs4 import BeautifulSoup
from tensorflow.keras.preprocessing import sequence
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Embedding
from tensorflow.keras.layers import LSTM
from tensorflow.keras.datasets import imdb

max_features = 20000
# cut texts after this number of words (among top max_features most common words)
maxlen = 80
batch_size = 32


def preprocess_text(text):
    # Removing html tags
    processed_text = BeautifulSoup(text, features="html.parser").get_text()
    # Remove capitalization
    processed_text = processed_text.lower()
    # Remove punctuations and numbers
    processed_text = re.sub(r"[^a-z'\s]", "", processed_text)
    # Remove quotations
    processed_text = re.sub(r"([^a-z])\'|\'([^a-z])", r"\1\2", processed_text)
    # Remove excessive whitespace
    processed_text = re.sub(r"\s+", r" ", processed_text)
    return processed_text


print("Loading data...")
(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)
print(len(x_train), "train sequences")
print(len(x_test), "test sequences")

print("Pad sequences (samples x time)")
x_train = sequence.pad_sequences(x_train, maxlen=maxlen)
x_test = sequence.pad_sequences(x_test, maxlen=maxlen)
print("x_train shape:", x_train.shape)
print("x_test shape:", x_test.shape)

print("Build model...")
model = Sequential()
model.add(Embedding(max_features, 128))
model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))
model.add(Dense(1, activation="sigmoid"))

# try using different optimizers and different optimizer configs
model.compile(loss="binary_crossentropy", optimizer="adam", metrics=["accuracy"])

print("Train...")
model.fit(
    x_train, y_train, batch_size=batch_size, epochs=3, validation_data=(x_test, y_test)
)
score, acc = model.evaluate(x_test, y_test, batch_size=batch_size)
print("Test score:", score)
print("Test accuracy:", acc)
print("Saving model...")
model_file_name = "my_model.h5"
model.save(model_file_name)
print("Model saved")


"""Now the model is trained, we need a way to convert a review to the numerical input the model expects.

1. Get the word index used by the dataset, which is a dictionary that maps strings to numbers
"""

word_index = imdb.get_word_index()

"""Get a sample from the imdb dataset (i.e. x_train[0]) along with it's text version (generated using the method below)"""

"""Create a review to numeric array function using the dictionary, plus a increment of 3, as per:

https://datascience.stackexchange.com/a/52128

and:

https://github.com/keras-team/keras/blob/master/keras/datasets/imdb.py#L14
"""

import nltk

nltk.download("punkt")


def convert_text_to_num_seq(text):
    text_word_list = nltk.word_tokenize(text)
    num_seq = [1]
    for word in text_word_list:
        try:
            num = word_index[word]
            num += 3
        except KeyError:
            num = 0
        if num >= max_features:
            num = 0
        num_seq.append(num)
    return num_seq


"""Test out the model with some example reviews"""

test_review_good = (
    "i have seen better movies but to be honest this was still pretty great"
)
test_review_bad = "i did not really like the movie that much"
result = model.predict([convert_text_to_num_seq(test_review_good)])
print(result)
if result[0][0] > 0.5:
    print("Positive")
else:
    print("Negative")
